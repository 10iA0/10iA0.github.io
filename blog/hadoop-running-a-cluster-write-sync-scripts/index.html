<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>Horseman, pass by.</title><meta charset=utf-8><meta name=description content="Ladder@I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script xync with shell."><meta name=author content="Jihang XIAO"><link rel=canonical href=https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/><meta property="og:title" content="Hadoop-Running a cluster-Write sync scripts"><meta property="og:description" content="I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script xync with shell."><meta property="og:type" content="article"><meta property="og:url" content="https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2021-06-21T02:18:00+00:00"><meta property="article:modified_time" content="2021-06-21T02:18:00+00:00"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-start-and-stop-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-appendix/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-configurate-a-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-preparation-on-servers/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-start-and-stop-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-appendix/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-configurate-a-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-preparation-on-servers/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Hadoop-Running a cluster-Write sync scripts"><meta name=twitter:description content="I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script xync with shell."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Blogs","item":"https://10iA0.github.io/blog/"},{"@type":"ListItem","position":3,"name":"Hadoop-Running a cluster-Write sync scripts","item":"https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hadoop-Running a cluster-Write sync scripts","name":"Hadoop-Running a cluster-Write sync scripts","description":"I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script xync with shell.\n","keywords":["scp","rsync","xsync"],"articleBody":"I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script xync with shell.\nscp (secure copy) copy files from a server to another server.\nBasic grammaring command parameter dir and fname destinated dir and fname scp -r $pdir/$fname $user@hadoop$host:$pdir/$fname 命令 递归 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称 Three examples Prerequisites: make sure /opt/module and /opt/software are in hadoop102, hadoop103 and hadoop104, and own:group are jihang:jihang\nsudo chown jihang:jihang -R /opt/module On hadoop102, copy /opt/module/jdk1.8.0_212 from hadoop102 to hadoop103 [jihang@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212 jihang@hadoop103:/opt/module On hadoop103, copy /opt/module/hadoop-3.1.3 from hadoop102 to hadoop103 [jihang@hadoop103 ~]$ scp -r jihang@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/ On hadoop103, copy all files on /opt/module from hadoop102 to hadoop104 [jihang@hadoop103 opt]$ scp -r jihang@hadoop102:/opt/module/* jihang@hadoop104:/opt/module rsync Difference between rsync and scp: rsync is faster and only update edited files.\nBasic grammaring command parameter dir and fname destinated dir and fname rsync -av $pdir/$fname $user@hadoop$host:$pdir/$fname 命令 参数 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称 parameter explanation -a copy -v dispaly processing One example copy all files on /opt/software from hadoop102 to hadoop103 [jihang@hadoop102 opt]$ rsync -av /opt/software/* jihang@hadoop103:/opt/software xsync There is no existed demand called xsync. I use a shell script to achieve my demand on copying files form a server to other servers. Why call this script xsync? Cause I think digit x is cool :)\ndemands copy files from a server to other servers on a loop as I wish.\nuse rsync to copy files： rsync -av /opt/module root@hadoop103:/opt/ use files I want to copy as argument(s) xsync [pdir/fname1] [pdir/fname2] store script on /home/jihang/bin so that I, the user jihang, could run xsync on system everywhere. Write script create a file xsync on /home/jihang/bin [jihang@hadoop102 opt]$ cd /home/jihang [jihang@hadoop102 ~]$ mkdir bin [jihang@hadoop102 ~]$ cd bin [jihang@hadoop102 bin]$ vim xsync and add content below\n#!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in hadoop102 hadoop103 hadoop104 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host \"mkdir -p $pdir\" rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done authorize xsync [jihang@hadoop102 bin]$ chmod +x xsync move script to /bin [jihang@hadoop102 bin]$ sudo cp xsync /bin/ test [jihang@hadoop102 ~]$ xsync /home/jihang/bin [jihang@hadoop102 bin]$ sudo xsync /bin/xsync ","wordCount":"438","inLanguage":"en","datePublished":"2021-06-21T02:18:00Z","dateModified":"2021-06-21T02:18:00Z","author":{"@type":"Person","name":"Jihang XIAO"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/"},"publisher":{"@type":"Organization","name":"Horseman, pass by.","logo":{"@type":"ImageObject","url":"https://10iA0.github.io/favicon.ico"}}}</script><link rel=icon type=image/png href=/images/sun.png sizes=16x16><link rel=apple-touch-icon href=/images/sun.png><link rel=manifest href=/images/sun.png><link rel=stylesheet href=/css/main.min.64bc8c4cb2304e84167c1583fa1b5de80f6d5adc95abed2e616dea0ea5680e01.css integrity="sha256-ZLyMTLIwToQWfBWD+htd6A9tWtyVq+0uYW3qDqVoDgE=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c098d85b5396dec4707ea2cead1445b4dc2ff0fc56b8dbbd9049d0d1c50ad237.js></script>
<script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/></a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/>Home</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives>Post</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/about>About</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/10iA0><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li><li class="navigation-item navigation-language"><a href=https://10iA0.github.io/zh/>中</a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>Hadoop-Running a cluster-Write sync scripts</h1></header><p><small>June 21, 2021&nbsp;· 438 words&nbsp;· 3 min</small>
<small>·
<a href=https://10iA0.github.io/tags/scp/>scp</a>
<a href=https://10iA0.github.io/tags/rsync/>rsync</a>
<a href=https://10iA0.github.io/tags/xsync/>xsync</a></small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#scp-secure-copy>scp (secure copy)</a><ul><li><a href=#basic-grammaring>Basic grammaring</a></li><li><a href=#three-examples>Three examples</a></li></ul></li><li><a href=#rsync>rsync</a><ul><li><a href=#basic-grammaring-1>Basic grammaring</a></li><li><a href=#one-example>One example</a></li></ul></li><li><a href=#xsync>xsync</a><ul><li><a href=#demands>demands</a></li><li><a href=#write-script>Write script</a></li></ul></li></ul></nav></div><section class=blog-content><p>I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script <code>xync</code> with shell.</p><h2 id=scp-secure-copy>scp (secure copy)</h2><p>copy files from a server to another server.</p><h3 id=basic-grammaring>Basic grammaring</h3><table><thead><tr><th>command</th><th>parameter</th><th>dir and fname</th><th>destinated dir and fname</th></tr></thead><tbody><tr><td>scp</td><td>-r</td><td>$pdir/$fname</td><td>$user@hadoop$host:$pdir/$fname</td></tr><tr><td>命令</td><td>递归</td><td>要拷贝的文件路径/名称</td><td>目的用户@主机:目的路径/名称</td></tr></tbody></table><h3 id=three-examples>Three examples</h3><p>Prerequisites: make sure <code>/opt/module</code> and <code>/opt/software</code> are in <code>hadoop102</code>, <code>hadoop103</code> and <code>hadoop104</code>, and own:group are <code>jihang:jihang</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>sudo chown jihang:jihang -R /opt/module
</span></span></code></pre></div><ol><li>On hadoop102, copy /opt/module/jdk1.8.0_212 from hadoop102 to hadoop103</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 ~<span style=color:#f92672>]</span>$ scp -r /opt/module/jdk1.8.0_212  jihang@hadoop103:/opt/module
</span></span></code></pre></div><ol start=2><li>On hadoop103, copy /opt/module/hadoop-3.1.3 from hadoop102 to hadoop103</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop103 ~<span style=color:#f92672>]</span>$ scp -r jihang@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/
</span></span></code></pre></div><ol start=3><li>On hadoop103, copy all files on /opt/module from hadoop102 to hadoop104</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop103 opt<span style=color:#f92672>]</span>$ scp -r jihang@hadoop102:/opt/module/* jihang@hadoop104:/opt/module
</span></span></code></pre></div><h2 id=rsync>rsync</h2><p>Difference between <code>rsync</code> and <code>scp</code>: rsync is faster and only update edited files.</p><h3 id=basic-grammaring-1>Basic grammaring</h3><table><thead><tr><th>command</th><th>parameter</th><th>dir and fname</th><th>destinated dir and fname</th></tr></thead><tbody><tr><td>rsync</td><td>-av</td><td>$pdir/$fname</td><td>$user@hadoop$host:$pdir/$fname</td></tr><tr><td>命令</td><td>参数</td><td>要拷贝的文件路径/名称</td><td>目的用户@主机:目的路径/名称</td></tr></tbody></table><table><thead><tr><th>parameter</th><th>explanation</th></tr></thead><tbody><tr><td>-a</td><td>copy</td></tr><tr><td>-v</td><td>dispaly processing</td></tr></tbody></table><h3 id=one-example>One example</h3><ol><li>copy all files on /opt/software from hadoop102 to hadoop103</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 opt<span style=color:#f92672>]</span>$ rsync -av /opt/software/* jihang@hadoop103:/opt/software
</span></span></code></pre></div><h2 id=xsync>xsync</h2><p>There is no existed demand called <code>xsync</code>. I use a shell script to achieve my demand on copying files form a server to other servers. Why call this script xsync? Cause I think digit x is cool :)</p><h3 id=demands>demands</h3><p>copy files from a server to other servers on a loop as I wish.</p><ol><li>use <code>rsync</code> to copy files：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>rsync -av /opt/module root@hadoop103:/opt/
</span></span></code></pre></div><ol start=2><li>use files I want to copy as argument(s)</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>xsync <span style=color:#f92672>[</span>pdir/fname1<span style=color:#f92672>]</span> <span style=color:#f92672>[</span>pdir/fname2<span style=color:#f92672>]</span>
</span></span></code></pre></div><ol start=3><li>store script on /home/jihang/bin so that I, the user <code>jihang</code>, could run <code>xsync</code> on system everywhere.</li></ol><h3 id=write-script>Write script</h3><ol><li>create a file <code>xsync</code> on /home/jihang/bin</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 opt<span style=color:#f92672>]</span>$ cd /home/jihang
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 ~<span style=color:#f92672>]</span>$ mkdir bin
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 ~<span style=color:#f92672>]</span>$ cd bin
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 bin<span style=color:#f92672>]</span>$ vim xsync
</span></span></code></pre></div><p>and add content below</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#75715e>#1. 判断参数个数</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span> $# -lt <span style=color:#ae81ff>1</span> <span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>  echo Not Enough Arguement!
</span></span><span style=display:flex><span>  exit;
</span></span><span style=display:flex><span><span style=color:#66d9ef>fi</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#2. 遍历集群所有机器</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> host in hadoop102 hadoop103 hadoop104
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>  echo <span style=color:#f92672>====================</span>  $host  <span style=color:#f92672>====================</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e>#3. 遍历所有目录，挨个发送</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> file in $@
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#4. 判断文件是否存在</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#f92672>[</span> -e $file <span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e>#5. 获取父目录</span>
</span></span><span style=display:flex><span>      pdir<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>cd -P <span style=color:#66d9ef>$(</span>dirname $file<span style=color:#66d9ef>)</span>; pwd<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e>#6. 获取当前文件的名称</span>
</span></span><span style=display:flex><span>      fname<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>basename $file<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>      ssh $host <span style=color:#e6db74>&#34;mkdir -p </span>$pdir<span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>      rsync -av $pdir/$fname $host:$pdir
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>
</span></span><span style=display:flex><span>      echo $file does not exists!
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fi</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span></code></pre></div><ol start=2><li>authorize xsync</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 bin<span style=color:#f92672>]</span>$ chmod +x xsync
</span></span></code></pre></div><ol start=3><li>move script to /bin</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 bin<span style=color:#f92672>]</span>$ sudo cp xsync /bin/
</span></span></code></pre></div><ol start=4><li>test</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 ~<span style=color:#f92672>]</span>$ xsync /home/jihang/bin
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop102 bin<span style=color:#f92672>]</span>$ sudo xsync /bin/xsync
</span></span></code></pre></div></section><div class=paginator><a class=prev href=https://10iA0.github.io/blog/hadoop-configurate-a-cluster/><span>&larr;&nbsp;&nbsp;</span><span>Hadoop-Configurate a cluster (Core, HDFS, MapReduce and YARN)</span></a>
<a class=next href=https://10iA0.github.io/blog/hadoop-preparation-on-servers/><span>Hadoop-Preparation on servers</span><span>&nbsp;&nbsp;&rarr;</span></a></div><div class=related-resources><h3>Related Resources</h3><nav><ul><li><a href=/blog/hadoop-start-and-stop-cluster/>Hadoop-Start and stop cluste</a></li><li><a href=/blog/hadoop-appendix/>Hadoop-Appendix</a></li><li><a href=/blog/hadoop-configurate-a-cluster/>Hadoop-Configurate a cluster (Core, HDFS, MapReduce and YARN)</a></li><li><a href=/blog/hadoop-preparation-on-servers/>Hadoop-Preparation on servers</a></li></ul></nav><nav><ul><li><a href=/blog/hadoop-start-and-stop-cluster/>Hadoop-Start and stop cluste</a></li><li><a href=/blog/hadoop-appendix/>Hadoop-Appendix</a></li><li><a href=/blog/hadoop-configurate-a-cluster/>Hadoop-Configurate a cluster (Core, HDFS, MapReduce and YARN)</a></li><li><a href=/blog/hadoop-preparation-on-servers/>Hadoop-Preparation on servers</a></li></ul></nav></div></article></div><footer class=footer><p>&copy; 2022 <a href=https://10iA0.github.io>Horseman, pass by.</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg></a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>