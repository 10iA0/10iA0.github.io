<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>Jihang Xiao</title><meta charset=utf-8><meta name=description content="Ladder@Setting up the development environment on Hadoop is the key point in big data computing."><meta name=author content="Jihang Xiao"><link rel=canonical href=https://10iA0.github.io/blog/draft_hdfs/><meta property="og:title" content="Fundamental development environment on Hadoop"><meta property="og:description" content="Setting up the development environment on Hadoop is the key point in big data computing."><meta property="og:type" content="article"><meta property="og:url" content="https://10iA0.github.io/blog/draft_hdfs/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2021-06-15T13:38:00+00:00"><meta property="article:modified_time" content="2021-06-15T13:38:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Fundamental development environment on Hadoop"><meta name=twitter:description content="Setting up the development environment on Hadoop is the key point in big data computing."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Blogs","item":"https://10iA0.github.io/blog/"},{"@type":"ListItem","position":3,"name":"Fundamental development environment on Hadoop","item":"https://10iA0.github.io/blog/draft_hdfs/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Fundamental development environment on Hadoop","name":"Fundamental development environment on Hadoop","description":"Setting up the development environment on Hadoop is the key point in big data computing.\n","keywords":[""],"articleBody":"Setting up the development environment on Hadoop is the key point in big data computing.\nSet up the development environment on Hadoop 1. Prepare a blueprint Prepare a development enviroment on virtual machine as a blueprint for further learning Hadoop. The buleprint is named as hadoop100 and configurated as:\nDRAM: 4G HDD: 50G 1.1 Install essential tools Install essential tools from yum repos for this operation system.\n# Test if the Internet is connected or not. [root@hadoop100 ~]# ping www.google.com [root@hadoop100 ~]# yum install -y epel-release [root@hadoop100 ~]# yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git 1.2 Stop and disable the firewall Turn off the firewall and disable its auto-start.\n[root@hadoop100 ~]# systemctl stop firewalld [root@hadoop100 ~]# systemctl disable firewalld 1.3 Create and authorize a user Create a user jihang for myself and change the password.\n[root@hadoop100 ~]# useradd jihang [root@hadoop100 ~]# passwd jihang Authorize user jihang as root to exectute sudo commands.\n[root@hadoop100 ~]# vim /etc/sudoers Edit the file /etc/sudoers, add a line on it as below:\n## Allow root to run any commands anywhere root ALL=(ALL) ALL jihang ALL=(ALL) NOPASSWD:ALL 1.4 Make and authorize folders Make folders module and software on /opt\n[root@hadoop100 ~]# mkdir /opt/module [root@hadoop100 ~]# mkdir /opt/software Edit folders module and software’s owner and group from root to jihang\n[root@hadoop100 ~]# chown jihang:jihang /opt/module [root@hadoop100 ~]# chown jihang:jihang /opt/software Check folders module, software’s owner and group\n[root@hadoop100 ~]# cd /opt/ [root@hadoop100 opt]# ll 总用量 12 drwxr-xr-x. 2 jihang jihang 4096 5月 28 17:18 module drwxr-xr-x. 2 root root 4096 9月 7 2017 rh drwxr-xr-x. 2 jihang jihang 4096 5月 28 17:18 software 1.5 Uninstall the defalut open JDK on system [root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps 1.6 Reboot Hadoop100 [root@hadoop100 ~]# reboot 2. Clone 3 systems Clone 3 systems hadoop102, hadoop103, hadoop104 from blueprint hadoop100\n2.1 Edit IP on cloned systems Take hadoop102 as an example below\nEdit the static IP\n[root@hadoop100 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33 add this content\nDEVICE=ens33 TYPE=Ethernet ONBOOT=yes BOOTPROTO=static NAME=\"ens33\" IPADDR=192.168.1.102 PREFIX=24 GATEWAY=192.168.1.2 DNS1=192.168.1.2 More details be refered to slides on Classes.\n2.2 Edit hostname Take hadoop102 as an example below\n[root@hadoop100 ~]# vim /etc/hostname hadoop102 2.3 Edit file hosts [root@hadoop100 ~]# vim /etc/hosts add this content\n192.168.1.100 hadoop100 192.168.1.101 hadoop101 192.168.1.102 hadoop102 192.168.1.103 hadoop103 192.168.1.104 hadoop104 192.168.1.105 hadoop105 192.168.1.106 hadoop106 192.168.1.107 hadoop107 192.168.1.108 hadoop108 Reboot hadoop102\n[root@hadoop100 ~]# reboot Edit file hosts on windows10\ncode C:\\Windows\\System32\\drivers\\etc\\hosts add this content\n192.168.1.100 hadoop100 192.168.1.101 hadoop101 192.168.1.102 hadoop102 192.168.1.103 hadoop103 192.168.1.104 hadoop104 192.168.1.105 hadoop105 192.168.1.106 hadoop106 192.168.1.107 hadoop107 192.168.1.108 hadoop108 3. Install JDK and Hadoop Take hadoop102 as an example below\n3.1 Install JDK Uninstall default JDK\n[jihang@hadoop102 ~]$ rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps I have downloaded tar jdk on opt/software/\n[jihang@hadoop102 ~]$ ls /opt/software/ hadoop-3.1.3.tar.gz jdk-8u212-linux-x64.tar.gz Unzip JDK to /opt/module\n[jihang@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/ Configurate JDK environmental variable\n[jihang@hadoop102 ~]$ sudo vim /etc/profile add as below\n#JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin save and quit\n:wq Refresh file /etc/profile, acitivate new environmental variable PATH\n[jihang@hadoop102 ~]$ source /etc/profile Check if JDK is installed well\n[jihang@hadoop102 ~]$ java -version java version \"1.8.0_212\" 3.2 Install Hadoop I have downloaded tar hadoop on opt/software/\n[jihang@hadoop102 ~]$ ls /opt/software/ hadoop-3.1.3.tar.gz jdk-8u212-linux-x64.tar.gz Unzip Hadoop to /opt/module\n[jihang@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/ Check if Hadoop is unzip well\n[jihang@hadoop102 software]$ ls /opt/module/ hadoop-3.1.3 Print present working dictionary\n[jihang@hadoop102 hadoop-3.1.3]$ pwd /opt/module/hadoop-3.1.3 Add Hadoop to environmental variable\nsudo vim /etc/profile add this content\n#HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin save and quit\n:wq Refresh file /etc/profile, acitivate new environmental variable PATH\n[jihang@hadoop102 hadoop-3.1.3]$ source /etc/profile Check if Hadoop is installed well\n[jihang@hadoop102 hadoop-3.1.3]$ hadoop version Hadoop 3.1.3 4. Hadoop’s FHS(Filesystem Hierarchy Standard) Check Hadoop’ FHS\n[jihang@hadoop102 hadoop-3.1.3]$ ll 总用量 52 drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 bin drwxr-xr-x. 3 jihang jihang 4096 5月 22 2017 etc drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 include drwxr-xr-x. 3 jihang jihang 4096 5月 22 2017 lib drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 libexec -rw-r--r--. 1 jihang jihang 15429 5月 22 2017 LICENSE.txt -rw-r--r--. 1 jihang jihang 101 5月 22 2017 NOTICE.txt -rw-r--r--. 1 jihang jihang 1366 5月 22 2017 README.txt drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 sbin drwxr-xr-x. 4 jihang jihang 4096 5月 22 2017 share Key files\nbin: store scripts running Hadoop’s service, like HDFS, YARN etc: store configuration files on Hadoop lib: store local library on Hadoop, like zip and unzip data sbin: store scripts to start or stop Hadoop’s service share: store Hadoop’s dependent jar packages, documentations, and official examples ","wordCount":"775","inLanguage":"en","datePublished":"2021-06-15T13:38:00Z","dateModified":"2021-06-15T13:38:00Z","author":{"@type":"Person","name":"Jihang Xiao"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://10iA0.github.io/blog/draft_hdfs/"},"publisher":{"@type":"Organization","name":"Jihang Xiao","logo":{"@type":"ImageObject","url":"https://10iA0.github.io/favicon.ico"}}}</script><link rel=icon type=image/png href=/images/sun.png sizes=16x16><link rel=apple-touch-icon href=/images/sun.png><link rel=manifest href=/images/sun.png><link rel=stylesheet href=/css/main.min.64bc8c4cb2304e84167c1583fa1b5de80f6d5adc95abed2e616dea0ea5680e01.css integrity="sha256-ZLyMTLIwToQWfBWD+htd6A9tWtyVq+0uYW3qDqVoDgE=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c098d85b5396dec4707ea2cead1445b4dc2ff0fc56b8dbbd9049d0d1c50ad237.js></script>
<script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/></a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/>Home</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives>Post</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/about>About</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/10iA0><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li><li class="navigation-item navigation-language"><a href=https://10iA0.github.io/zh/>中</a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>Fundamental development environment on Hadoop</h1></header><p><small>June 15, 2021&nbsp;· 775 words&nbsp;· 4 min</small>
<small></small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#set-up-the-development-environment-on-hadoop>Set up the development environment on Hadoop</a><ul><li><a href=#1-prepare-a-blueprint>1. Prepare a blueprint</a></li><li><a href=#2-clone-3-systems>2. Clone 3 systems</a></li><li><a href=#3-install-jdk-and-hadoop>3. Install JDK and Hadoop</a></li><li><a href=#4-hadoops-fhsfilesystem-hierarchy-standard>4. Hadoop&rsquo;s FHS(Filesystem Hierarchy Standard)</a></li></ul></li></ul></nav></div><section class=blog-content><p>Setting up the development environment on Hadoop is the key point in big data computing.</p><h2 id=set-up-the-development-environment-on-hadoop>Set up the development environment on Hadoop</h2><h3 id=1-prepare-a-blueprint>1. Prepare a blueprint</h3><p>Prepare a development enviroment on virtual machine as a blueprint for further learning Hadoop. The buleprint is named as <code>hadoop100</code> and configurated as:</p><ul><li>DRAM: 4G</li><li>HDD: 50G</li></ul><h4 id=11-install-essential-tools>1.1 Install essential tools</h4><p>Install essential tools from yum repos for this operation system.</p><pre tabindex=0><code># Test if the Internet is connected or not.
[root@hadoop100 ~]# ping www.google.com

[root@hadoop100 ~]# yum install -y epel-release
[root@hadoop100 ~]# yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git
</code></pre><h4 id=12-stop-and-disable-the-firewall>1.2 Stop and disable the firewall</h4><p>Turn off the firewall and disable its auto-start.</p><pre tabindex=0><code>[root@hadoop100 ~]# systemctl stop firewalld
[root@hadoop100 ~]# systemctl disable firewalld
</code></pre><h4 id=13-create-and-authorize-a-user>1.3 Create and authorize a user</h4><p>Create a user <code>jihang</code> for myself and change the password.</p><pre tabindex=0><code>[root@hadoop100 ~]# useradd jihang
[root@hadoop100 ~]# passwd jihang
</code></pre><p>Authorize user <code>jihang</code> as <code>root</code> to exectute <code>sudo</code> commands.</p><pre tabindex=0><code>[root@hadoop100 ~]# vim /etc/sudoers
</code></pre><p>Edit the file <code>/etc/sudoers</code>, add a line on it as below:</p><pre tabindex=0><code>## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
jihang   ALL=(ALL)     NOPASSWD:ALL
</code></pre><h4 id=14-make-and-authorize-folders>1.4 Make and authorize folders</h4><p>Make folders <code>module</code> and <code>software</code> on <code>/opt</code></p><pre tabindex=0><code>[root@hadoop100 ~]# mkdir /opt/module
[root@hadoop100 ~]# mkdir /opt/software
</code></pre><p>Edit folders <code>module</code> and <code>software</code>&rsquo;s owner and group from <code>root</code> to <code>jihang</code></p><pre tabindex=0><code>[root@hadoop100 ~]# chown jihang:jihang /opt/module 
[root@hadoop100 ~]# chown jihang:jihang /opt/software
</code></pre><p>Check folders <code>module</code>, <code>software</code>&rsquo;s owner and group</p><pre tabindex=0><code>[root@hadoop100 ~]# cd /opt/
[root@hadoop100 opt]# ll
总用量 12
drwxr-xr-x. 2 jihang jihang 4096 5月  28 17:18 module
drwxr-xr-x. 2 root    root    4096 9月   7 2017 rh
drwxr-xr-x. 2 jihang jihang 4096 5月  28 17:18 software
</code></pre><h4 id=15-uninstall-the-defalut-open-jdk-on-system>1.5 Uninstall the defalut <code>open JDK</code> on system</h4><pre tabindex=0><code>[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
</code></pre><h4 id=16-reboot-hadoop100>1.6 Reboot Hadoop100</h4><pre tabindex=0><code>[root@hadoop100 ~]# reboot
</code></pre><h3 id=2-clone-3-systems>2. Clone 3 systems</h3><p>Clone 3 systems <code>hadoop102</code>, <code>hadoop103</code>, <code>hadoop104</code> from blueprint <code>hadoop100</code></p><h4 id=21-edit-ip-on-cloned-systems>2.1 Edit IP on cloned systems</h4><p>Take <code>hadoop102</code> as an example below</p><p>Edit the static IP</p><pre tabindex=0><code>[root@hadoop100 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33
</code></pre><p>add this content</p><pre tabindex=0><code>DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME=&#34;ens33&#34;
IPADDR=192.168.1.102
PREFIX=24
GATEWAY=192.168.1.2
DNS1=192.168.1.2
</code></pre><p>More details be refered to slides on Classes.</p><h4 id=22-edit-hostname>2.2 Edit hostname</h4><p>Take <code>hadoop102</code> as an example below</p><pre tabindex=0><code>[root@hadoop100 ~]# vim /etc/hostname
hadoop102
</code></pre><h4 id=23-edit-file-hosts>2.3 Edit file <code>hosts</code></h4><pre tabindex=0><code>[root@hadoop100 ~]# vim /etc/hosts
</code></pre><p>add this content</p><pre tabindex=0><code>192.168.1.100 hadoop100
192.168.1.101 hadoop101
192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104
192.168.1.105 hadoop105
192.168.1.106 hadoop106
192.168.1.107 hadoop107
192.168.1.108 hadoop108
</code></pre><p>Reboot hadoop102</p><pre tabindex=0><code>[root@hadoop100 ~]# reboot
</code></pre><p>Edit file <code>hosts</code> on windows10</p><pre tabindex=0><code>code C:\Windows\System32\drivers\etc\hosts
</code></pre><p>add this content</p><pre tabindex=0><code>192.168.1.100 hadoop100
192.168.1.101 hadoop101
192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104
192.168.1.105 hadoop105
192.168.1.106 hadoop106
192.168.1.107 hadoop107
192.168.1.108 hadoop108
</code></pre><h3 id=3-install-jdk-and-hadoop>3. Install JDK and Hadoop</h3><p>Take <code>hadoop102</code> as an example below</p><h4 id=31-install-jdk>3.1 Install JDK</h4><p>Uninstall default JDK</p><pre tabindex=0><code>[jihang@hadoop102 ~]$ rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
</code></pre><p>I have downloaded tar <code>jdk</code> on <code>opt/software/</code></p><pre tabindex=0><code>[jihang@hadoop102 ~]$ ls /opt/software/
hadoop-3.1.3.tar.gz  jdk-8u212-linux-x64.tar.gz
</code></pre><p>Unzip JDK to <code>/opt/module</code></p><pre tabindex=0><code>[jihang@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
</code></pre><p>Configurate JDK environmental variable</p><pre tabindex=0><code>[jihang@hadoop102 ~]$ sudo vim /etc/profile
</code></pre><p>add as below</p><pre tabindex=0><code>#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
</code></pre><p>save and quit</p><pre tabindex=0><code>:wq
</code></pre><p>Refresh file <code>/etc/profile</code>, acitivate new environmental variable <code>PATH</code></p><pre tabindex=0><code>[jihang@hadoop102 ~]$ source /etc/profile
</code></pre><p>Check if JDK is installed well</p><pre tabindex=0><code>[jihang@hadoop102 ~]$ java -version
java version &#34;1.8.0_212&#34;
</code></pre><h4 id=32-install-hadoop>3.2 Install Hadoop</h4><p>I have downloaded tar <code>hadoop</code> on <code>opt/software/</code></p><pre tabindex=0><code>[jihang@hadoop102 ~]$ ls /opt/software/
hadoop-3.1.3.tar.gz  jdk-8u212-linux-x64.tar.gz
</code></pre><p>Unzip Hadoop to <code>/opt/module</code></p><pre tabindex=0><code>[jihang@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
</code></pre><p>Check if Hadoop is unzip well</p><pre tabindex=0><code>[jihang@hadoop102 software]$ ls /opt/module/
hadoop-3.1.3
</code></pre><p>Print present working dictionary</p><pre tabindex=0><code>[jihang@hadoop102 hadoop-3.1.3]$ pwd
/opt/module/hadoop-3.1.3
</code></pre><p>Add Hadoop to environmental variable</p><pre tabindex=0><code>sudo vim /etc/profile
</code></pre><p>add this content</p><pre tabindex=0><code>#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
</code></pre><p>save and quit</p><pre tabindex=0><code>:wq
</code></pre><p>Refresh file /etc/profile, acitivate new environmental variable <code>PATH</code></p><pre tabindex=0><code>[jihang@hadoop102 hadoop-3.1.3]$ source /etc/profile
</code></pre><p>Check if Hadoop is installed well</p><pre tabindex=0><code>[jihang@hadoop102 hadoop-3.1.3]$ hadoop version
Hadoop 3.1.3
</code></pre><h3 id=4-hadoops-fhsfilesystem-hierarchy-standard>4. Hadoop&rsquo;s FHS(Filesystem Hierarchy Standard)</h3><p>Check Hadoop&rsquo; FHS</p><pre tabindex=0><code>[jihang@hadoop102 hadoop-3.1.3]$ ll
总用量 52
drwxr-xr-x. 2 jihang jihang  4096 5月  22 2017 bin
drwxr-xr-x. 3 jihang jihang  4096 5月  22 2017 etc
drwxr-xr-x. 2 jihang jihang  4096 5月  22 2017 include
drwxr-xr-x. 3 jihang jihang  4096 5月  22 2017 lib
drwxr-xr-x. 2 jihang jihang  4096 5月  22 2017 libexec
-rw-r--r--. 1 jihang jihang 15429 5月  22 2017 LICENSE.txt
-rw-r--r--. 1 jihang jihang   101 5月  22 2017 NOTICE.txt
-rw-r--r--. 1 jihang jihang  1366 5月  22 2017 README.txt
drwxr-xr-x. 2 jihang jihang  4096 5月  22 2017 sbin
drwxr-xr-x. 4 jihang jihang  4096 5月  22 2017 share
</code></pre><p>Key files</p><ul><li>bin: store scripts running Hadoop&rsquo;s service, like HDFS, YARN</li><li>etc: store configuration files on Hadoop</li><li>lib: store local library on Hadoop, like zip and unzip data</li><li>sbin: store scripts to start or stop Hadoop&rsquo;s service</li><li>share: store Hadoop&rsquo;s dependent jar packages, documentations, and official examples</li></ul></section><div class=paginator><a class=prev href=https://10iA0.github.io/blog/configurating-wsl/><span>&larr;&nbsp;&nbsp;</span><span>Configurating WSL</span></a>
<a class=next href=https://10iA0.github.io/blog/os/><span>os</span><span>&nbsp;&nbsp;&rarr;</span></a></div><div class=related-resources><h3>Related Resources</h3></div></article></div><footer class=footer><p>&copy; 2022 <a href=https://10iA0.github.io>Jihang Xiao</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg></a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>