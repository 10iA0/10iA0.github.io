<!doctype html><html lang=en><head><meta name=viewport content="width=device-width,initial-scale=1"><title>Horseman, pass by.</title><meta charset=utf-8><meta name=description content="Ladder@Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines."><meta name=author content="Jihang XIAO"><link rel=canonical href=https://10iA0.github.io/blog/hadoop-preparation-on-servers/><meta property="og:title" content="Hadoop-Preparation on servers"><meta property="og:description" content="Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines."><meta property="og:type" content="article"><meta property="og:url" content="https://10iA0.github.io/blog/hadoop-preparation-on-servers/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2021-06-15T13:38:00+00:00"><meta property="article:modified_time" content="2021-06-15T13:38:00+00:00"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-start-and-stop-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-appendix/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-configurate-a-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-start-and-stop-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-appendix/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-configurate-a-cluster/"><meta property="og:see_also" content="https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Hadoop-Preparation on servers"><meta name=twitter:description content="Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Blogs","item":"https://10iA0.github.io/blog/"},{"@type":"ListItem","position":3,"name":"Hadoop-Preparation on servers","item":"https://10iA0.github.io/blog/hadoop-preparation-on-servers/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Hadoop-Preparation on servers","name":"Hadoop-Preparation on servers","description":"Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines.\n","keywords":["Linux minimal installation","firewall","IP","hostname","hosts"],"articleBody":"Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines.\nPrepare a server as blueprint Prepare a virtual machine as a blueprint and set up the development environment on it for further learning Hadoop. The buleprint is named as hadoop100 and has DRAM(4G) and HDD(50G).\nFix bugs for Linux minimal installation The minimal installation leads some lack of essential extentions. Fortunately, these packages can be installed from yum repository.\n# Test if the Internet is connected or not. [root@hadoop100 ~]$ ping www.google.com [root@hadoop100 ~]$ yum install -y epel-release [root@hadoop100 ~]$ yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git Stop and disable the firewall Turn off disable the firewall in case it automatically start.\n[root@hadoop100 ~]$ systemctl stop firewalld [root@hadoop100 ~]$ systemctl disable firewalld Create and authorize a user Create a user jihang for myself and change its password.\n[root@hadoop100 ~]$ useradd jihang [root@hadoop100 ~]$ passwd jihang Authorize user jihang as root to exectute sudo commands.\n[root@hadoop100 ~]$ vim /etc/sudoers Edit the file /etc/sudoers, and add content below on the file:\n## Allow root to run any commands anywhere root ALL=(ALL) ALL jihang ALL=(ALL) NOPASSWD:ALL Create and authorize folders Make folders module and software on /opt\n[root@hadoop100 ~]$ mkdir /opt/module [root@hadoop100 ~]$ mkdir /opt/software Change folders module and software’s owner and group from root to jihang\n[root@hadoop100 ~]$ chown jihang:jihang /opt/module [root@hadoop100 ~]$ chown jihang:jihang /opt/software [root@hadoop100 ~]$ cd /opt/ [root@hadoop100 opt]$ ll 总用量 12 drwxr-xr-x. 2 jihang jihang 4096 5月 28 17:18 module drwxr-xr-x. 2 root root 4096 9月 7 2017 rh drwxr-xr-x. 2 jihang jihang 4096 5月 28 17:18 software Install JDK and Hadoop Install JDK Uninstall default JDK\n[jihang@hadoop100 ~]$ rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps The tar of jdk is downloaded on opt/software/\n[jihang@hadoop100 ~]$ ls /opt/software/ hadoop-3.1.3.tar.gz jdk-8u212-linux-x64.tar.gz Unzip JDK to /opt/module\n[jihang@hadoop100 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/ Configurate JDK environmental variable\n[jihang@hadoop100 ~]$ sudo vim /etc/profile.d/xenv.sh add content as below: #JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin save and quit: :wq Refresh file /etc/profile and check if JDK was installed well\n[jihang@hadoop100 ~]$ source /etc/profile [jihang@hadoop100 ~]$ java -version java version \"1.8.0_212\" Install Hadoop The tar of hadoop is downloaded on opt/software/\n[jihang@hadoop100 ~]$ ls /opt/software/ hadoop-3.1.3.tar.gz jdk-8u212-linux-x64.tar.gz Unzip Hadoop to /opt/module\n[jihang@hadoop100 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/ Configurate Hadoop environmental variable\nsudo vim /etc/profile add this content #HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin save and quit :wq Refresh file /etc/profile and check if Hadoop is installed well\n[jihang@hadoop100 hadoop-3.1.3]$ source /etc/profile [jihang@hadoop100 hadoop-3.1.3]$ hadoop version Hadoop 3.1.3 Introduce Hadoop’s filesystem hierarchy\n[jihang@hadoop100 hadoop-3.1.3]$ ll 总用量 52 drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 bin drwxr-xr-x. 3 jihang jihang 4096 5月 22 2017 etc drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 include drwxr-xr-x. 3 jihang jihang 4096 5月 22 2017 lib drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 libexec -rw-r--r--. 1 jihang jihang 15429 5月 22 2017 LICENSE.txt -rw-r--r--. 1 jihang jihang 101 5月 22 2017 NOTICE.txt -rw-r--r--. 1 jihang jihang 1366 5月 22 2017 README.txt drwxr-xr-x. 2 jihang jihang 4096 5月 22 2017 sbin drwxr-xr-x. 4 jihang jihang 4096 5月 22 2017 share Key files\nbin: store scripts running Hadoop’s service, like HDFS, YARN etc: store configuration files on Hadoop lib: store local library on Hadoop, like zip and unzip data sbin: store scripts to start or stop Hadoop’s service share: store Hadoop’s dependent jar packages, documentations, and official examples Edit the file hosts Linux [root@hadoop100 ~]$ vim /etc/hosts add this content\n192.168.1.100 hadoop100 192.168.1.101 hadoop101 192.168.1.102 hadoop102 192.168.1.103 hadoop103 192.168.1.104 hadoop104 192.168.1.105 hadoop105 192.168.1.106 hadoop106 192.168.1.107 hadoop107 192.168.1.108 hadoop108 Windows (win10) code C:\\Windows\\System32\\drivers\\etc\\hosts add this content\n192.168.1.100 hadoop100 192.168.1.101 hadoop101 192.168.1.102 hadoop102 192.168.1.103 hadoop103 192.168.1.104 hadoop104 192.168.1.105 hadoop105 192.168.1.106 hadoop106 192.168.1.107 hadoop107 192.168.1.108 hadoop108 Clone 3 servers (from the blueprint) Clone 3 servers hadoop102, hadoop103, hadoop104 from the blueprint hadoop100\nEdit IP Take hadoop102 as an example below\nEdit the static IP\n[root@hadoop102 ~]$ vim /etc/sysconfig/network-scripts/ifcfg-ens33 add this content DEVICE=ens33 TYPE=Ethernet ONBOOT=yes BOOTPROTO=static NAME=\"ens33\" IPADDR=192.168.1.102 PREFIX=24 GATEWAY=192.168.1.2 DNS1=192.168.1.2 More details be refered to slides on Classes.\nEdit hostname Take hadoop102 as an example below\n[root@hadoop102 ~]$ vim /etc/hostname hadoop102 ","wordCount":"733","inLanguage":"en","datePublished":"2021-06-15T13:38:00Z","dateModified":"2021-06-15T13:38:00Z","author":{"@type":"Person","name":"Jihang XIAO"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://10iA0.github.io/blog/hadoop-preparation-on-servers/"},"publisher":{"@type":"Organization","name":"Horseman, pass by.","logo":{"@type":"ImageObject","url":"https://10iA0.github.io/favicon.ico"}}}</script><link rel=icon type=image/png href=/images/sun.png sizes=16x16><link rel=apple-touch-icon href=/images/sun.png><link rel=manifest href=/images/sun.png><link rel=stylesheet href=/css/main.min.64bc8c4cb2304e84167c1583fa1b5de80f6d5adc95abed2e616dea0ea5680e01.css integrity="sha256-ZLyMTLIwToQWfBWD+htd6A9tWtyVq+0uYW3qDqVoDgE=" crossorigin=anonymous media=screen><link rel=stylesheet href=/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css><script src=/js/highlight.min.min.c098d85b5396dec4707ea2cead1445b4dc2ff0fc56b8dbbd9049d0d1c50ad237.js></script>
<script>hljs.highlightAll()</script><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script></head><body><main class=wrapper><nav class=navigation><section class=container><a class=navigation-brand href=/></a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><span></span><span></span><span></span></label><ul class=navigation-list id=navigation-list><li class="navigation-item navigation-menu"><a class=navigation-link href=/>Home</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/archives>Post</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/tags>Tags</a></li><li class="navigation-item navigation-menu"><a class=navigation-link href=/about>About</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class="navigation-item navigation-social"><a class=navigation-link href=https://github.com/10iA0><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li class="navigation-item navigation-dark"><button id=mode type=button aria-label="toggle user light or dark theme">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></li><li class="navigation-item navigation-language"><a href=https://10iA0.github.io/zh/>中</a></li></ul></section></nav><div id=content><article class=blog-single><header class=blog-title><h1>Hadoop-Preparation on servers</h1></header><p><small>June 15, 2021&nbsp;· 733 words&nbsp;· 4 min</small>
<small>·
<a href=https://10iA0.github.io/tags/linux-minimal-installation/>Linux minimal installation</a>
<a href=https://10iA0.github.io/tags/firewall/>firewall</a>
<a href=https://10iA0.github.io/tags/ip/>IP</a>
<a href=https://10iA0.github.io/tags/hostname/>hostname</a>
<a href=https://10iA0.github.io/tags/hosts/>hosts</a></small><p><div class=blog-toc><nav id=TableOfContents><ul><li><a href=#prepare-a-server-as-blueprint>Prepare a server as blueprint</a><ul><li><a href=#fix-bugs-for-linux-minimal-installation>Fix bugs for Linux minimal installation</a></li><li><a href=#stop-and-disable-the-firewall>Stop and disable the firewall</a></li><li><a href=#create-and-authorize-a-user>Create and authorize a user</a></li><li><a href=#create-and-authorize-folders>Create and authorize folders</a></li><li><a href=#install-jdk-and-hadoop>Install JDK and Hadoop</a></li><li><a href=#edit-the-file-hosts>Edit the file <code>hosts</code></a></li></ul></li><li><a href=#clone-3-servers-from-the-blueprint>Clone 3 servers (from the blueprint)</a><ul><li><a href=#edit-ip>Edit IP</a></li><li><a href=#edit-hostname>Edit hostname</a></li></ul></li></ul></nav></div><section class=blog-content><p>Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines.</p><h2 id=prepare-a-server-as-blueprint>Prepare a server as blueprint</h2><p>Prepare a virtual machine as a blueprint and set up the development environment on it for further learning Hadoop. The buleprint is named as <code>hadoop100</code> and has <code>DRAM(4G)</code> and <code>HDD(50G)</code>.</p><h3 id=fix-bugs-for-linux-minimal-installation>Fix bugs for Linux minimal installation</h3><p>The minimal installation leads some lack of essential extentions. Fortunately, these packages can be installed from yum repository.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e># Test if the Internet is connected or not.</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ ping www.google.com
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ yum install -y epel-release
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git
</span></span></code></pre></div><h3 id=stop-and-disable-the-firewall>Stop and disable the firewall</h3><p>Turn off disable the firewall in case it automatically start.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ systemctl stop firewalld
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ systemctl disable firewalld
</span></span></code></pre></div><h3 id=create-and-authorize-a-user>Create and authorize a user</h3><p>Create a user <code>jihang</code> for myself and change its password.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ useradd jihang
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ passwd jihang
</span></span></code></pre></div><p>Authorize user <code>jihang</code> as <code>root</code> to exectute <code>sudo</code> commands.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ vim /etc/sudoers
</span></span></code></pre></div><p>Edit the file <code>/etc/sudoers</code>, and add content below on the file:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>## Allow root to run any commands anywhere</span>
</span></span><span style=display:flex><span>root    ALL<span style=color:#f92672>=(</span>ALL<span style=color:#f92672>)</span>     ALL
</span></span><span style=display:flex><span>jihang   ALL<span style=color:#f92672>=(</span>ALL<span style=color:#f92672>)</span>     NOPASSWD:ALL
</span></span></code></pre></div><h3 id=create-and-authorize-folders>Create and authorize folders</h3><p>Make folders <code>module</code> and <code>software</code> on <code>/opt</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ mkdir /opt/module
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ mkdir /opt/software
</span></span></code></pre></div><p>Change folders <code>module</code> and <code>software</code>&rsquo;s owner and group from <code>root</code> to <code>jihang</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ chown jihang:jihang /opt/module 
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ chown jihang:jihang /opt/software
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ cd /opt/
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 opt<span style=color:#f92672>]</span>$ ll
</span></span><span style=display:flex><span>总用量 <span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>28</span> 17:18 module
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> root    root    <span style=color:#ae81ff>4096</span> 9月   <span style=color:#ae81ff>7</span> <span style=color:#ae81ff>2017</span> rh
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>28</span> 17:18 software
</span></span></code></pre></div><h3 id=install-jdk-and-hadoop>Install JDK and Hadoop</h3><h4 id=install-jdk>Install JDK</h4><p>Uninstall default JDK</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps
</span></span></code></pre></div><p>The tar of <code>jdk</code> is downloaded on <code>opt/software/</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ ls /opt/software/
</span></span><span style=display:flex><span>hadoop-3.1.3.tar.gz  jdk-8u212-linux-x64.tar.gz
</span></span></code></pre></div><p>Unzip JDK to <code>/opt/module</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 software<span style=color:#f92672>]</span>$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
</span></span></code></pre></div><p>Configurate JDK environmental variable</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ sudo vim /etc/profile.d/xenv.sh
</span></span></code></pre></div><ul><li>add content as below:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#JAVA_HOME</span>
</span></span><span style=display:flex><span>export JAVA_HOME<span style=color:#f92672>=</span>/opt/module/jdk1.8.0_212
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$PATH:$JAVA_HOME/bin
</span></span></code></pre></div><ul><li>save and quit:</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>:wq
</span></span></code></pre></div><p>Refresh file <code>/etc/profile</code> and check if JDK was installed well</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ source /etc/profile
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ java -version
</span></span><span style=display:flex><span>java version <span style=color:#e6db74>&#34;1.8.0_212&#34;</span>
</span></span></code></pre></div><h4 id=install-hadoop>Install Hadoop</h4><p>The tar of <code>hadoop</code> is downloaded on <code>opt/software/</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 ~<span style=color:#f92672>]</span>$ ls /opt/software/
</span></span><span style=display:flex><span>hadoop-3.1.3.tar.gz  jdk-8u212-linux-x64.tar.gz
</span></span></code></pre></div><p>Unzip Hadoop to <code>/opt/module</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 software<span style=color:#f92672>]</span>$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
</span></span></code></pre></div><p>Configurate Hadoop environmental variable</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>sudo vim /etc/profile
</span></span></code></pre></div><ul><li>add this content</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#HADOOP_HOME</span>
</span></span><span style=display:flex><span>export HADOOP_HOME<span style=color:#f92672>=</span>/opt/module/hadoop-3.1.3
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$PATH:$HADOOP_HOME/bin
</span></span><span style=display:flex><span>export PATH<span style=color:#f92672>=</span>$PATH:$HADOOP_HOME/sbin
</span></span></code></pre></div><ul><li>save and quit</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>:wq
</span></span></code></pre></div><p>Refresh file /etc/profile and check if Hadoop is installed well</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 hadoop-3.1.3<span style=color:#f92672>]</span>$ source /etc/profile
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 hadoop-3.1.3<span style=color:#f92672>]</span>$ hadoop version
</span></span><span style=display:flex><span>Hadoop 3.1.3
</span></span></code></pre></div><p>Introduce Hadoop&rsquo;s filesystem hierarchy</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>jihang@hadoop100 hadoop-3.1.3<span style=color:#f92672>]</span>$ ll
</span></span><span style=display:flex><span>总用量 <span style=color:#ae81ff>52</span>
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> bin
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>3</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> etc
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> include
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>3</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> lib
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> libexec
</span></span><span style=display:flex><span>-rw-r--r--. <span style=color:#ae81ff>1</span> jihang jihang <span style=color:#ae81ff>15429</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> LICENSE.txt
</span></span><span style=display:flex><span>-rw-r--r--. <span style=color:#ae81ff>1</span> jihang jihang   <span style=color:#ae81ff>101</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> NOTICE.txt
</span></span><span style=display:flex><span>-rw-r--r--. <span style=color:#ae81ff>1</span> jihang jihang  <span style=color:#ae81ff>1366</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> README.txt
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>2</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> sbin
</span></span><span style=display:flex><span>drwxr-xr-x. <span style=color:#ae81ff>4</span> jihang jihang  <span style=color:#ae81ff>4096</span> 5月  <span style=color:#ae81ff>22</span> <span style=color:#ae81ff>2017</span> share
</span></span></code></pre></div><p>Key files</p><ul><li>bin: store scripts running Hadoop&rsquo;s service, like HDFS, YARN</li><li>etc: store configuration files on Hadoop</li><li>lib: store local library on Hadoop, like zip and unzip data</li><li>sbin: store scripts to start or stop Hadoop&rsquo;s service</li><li>share: store Hadoop&rsquo;s dependent jar packages, documentations, and official examples</li></ul><h3 id=edit-the-file-hosts>Edit the file <code>hosts</code></h3><h4 id=linux>Linux</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop100 ~<span style=color:#f92672>]</span>$ vim /etc/hosts
</span></span></code></pre></div><p>add this content</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>192.168.1.100 hadoop100
</span></span><span style=display:flex><span>192.168.1.101 hadoop101
</span></span><span style=display:flex><span>192.168.1.102 hadoop102
</span></span><span style=display:flex><span>192.168.1.103 hadoop103
</span></span><span style=display:flex><span>192.168.1.104 hadoop104
</span></span><span style=display:flex><span>192.168.1.105 hadoop105
</span></span><span style=display:flex><span>192.168.1.106 hadoop106
</span></span><span style=display:flex><span>192.168.1.107 hadoop107
</span></span><span style=display:flex><span>192.168.1.108 hadoop108
</span></span></code></pre></div><h4 id=windows-win10>Windows (win10)</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>code C:<span style=color:#ae81ff>\W</span>indows<span style=color:#ae81ff>\S</span>ystem32<span style=color:#ae81ff>\d</span>rivers<span style=color:#ae81ff>\e</span>tc<span style=color:#ae81ff>\h</span>osts
</span></span></code></pre></div><p>add this content</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>192.168.1.100 hadoop100
</span></span><span style=display:flex><span>192.168.1.101 hadoop101
</span></span><span style=display:flex><span>192.168.1.102 hadoop102
</span></span><span style=display:flex><span>192.168.1.103 hadoop103
</span></span><span style=display:flex><span>192.168.1.104 hadoop104
</span></span><span style=display:flex><span>192.168.1.105 hadoop105
</span></span><span style=display:flex><span>192.168.1.106 hadoop106
</span></span><span style=display:flex><span>192.168.1.107 hadoop107
</span></span><span style=display:flex><span>192.168.1.108 hadoop108
</span></span></code></pre></div><h2 id=clone-3-servers-from-the-blueprint>Clone 3 servers (from the blueprint)</h2><p>Clone 3 servers <code>hadoop102</code>, <code>hadoop103</code>, <code>hadoop104</code> from the blueprint <code>hadoop100</code></p><h3 id=edit-ip>Edit IP</h3><p>Take <code>hadoop102</code> as an example below</p><p>Edit the static IP</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop102 ~<span style=color:#f92672>]</span>$ vim /etc/sysconfig/network-scripts/ifcfg-ens33
</span></span></code></pre></div><ul><li>add this content</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>DEVICE<span style=color:#f92672>=</span>ens33
</span></span><span style=display:flex><span>TYPE<span style=color:#f92672>=</span>Ethernet
</span></span><span style=display:flex><span>ONBOOT<span style=color:#f92672>=</span>yes
</span></span><span style=display:flex><span>BOOTPROTO<span style=color:#f92672>=</span>static
</span></span><span style=display:flex><span>NAME<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ens33&#34;</span>
</span></span><span style=display:flex><span>IPADDR<span style=color:#f92672>=</span>192.168.1.102
</span></span><span style=display:flex><span>PREFIX<span style=color:#f92672>=</span><span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span>GATEWAY<span style=color:#f92672>=</span>192.168.1.2
</span></span><span style=display:flex><span>DNS1<span style=color:#f92672>=</span>192.168.1.2
</span></span></code></pre></div><p>More details be refered to slides on Classes.</p><h3 id=edit-hostname>Edit hostname</h3><p>Take <code>hadoop102</code> as an example below</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>root@hadoop102 ~<span style=color:#f92672>]</span>$ vim /etc/hostname
</span></span><span style=display:flex><span>hadoop102
</span></span></code></pre></div></section><div class=paginator><a class=prev href=https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/><span>&larr;&nbsp;&nbsp;</span><span>Hadoop-Running a cluster-Write sync scripts</span></a>
<a class=next href=https://10iA0.github.io/blog/introduction-of-spark/><span>Introduction of Spark</span><span>&nbsp;&nbsp;&rarr;</span></a></div><div class=related-resources><h3>Related Resources</h3><nav><ul><li><a href=/blog/hadoop-start-and-stop-cluster/>Hadoop-Start and stop cluste</a></li><li><a href=/blog/hadoop-appendix/>Hadoop-Appendix</a></li><li><a href=/blog/hadoop-configurate-a-cluster/>Hadoop-Configurate a cluster (Core, HDFS, MapReduce and YARN)</a></li><li><a href=/blog/hadoop-running-a-cluster-write-sync-scripts/>Hadoop-Running a cluster-Write sync scripts</a></li></ul></nav><nav><ul><li><a href=/blog/hadoop-start-and-stop-cluster/>Hadoop-Start and stop cluste</a></li><li><a href=/blog/hadoop-appendix/>Hadoop-Appendix</a></li><li><a href=/blog/hadoop-configurate-a-cluster/>Hadoop-Configurate a cluster (Core, HDFS, MapReduce and YARN)</a></li><li><a href=/blog/hadoop-running-a-cluster-write-sync-scripts/>Hadoop-Running a cluster-Write sync scripts</a></li></ul></nav></div></article></div><footer class=footer><p>&copy; 2022 <a href=https://10iA0.github.io>Horseman, pass by.</a>
Powered by
<a href=https://gohugo.io/ rel=noopener target=_blank>Hugo️️</a>
<a href=https://github.com/guangzhengli/hugo-theme-ladder rel=noopener target=_blank>Ladder</a>
️</p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-up"><line x1="12" y1="19" x2="12" y2="5"/><polyline points="5 12 12 5 19 12"/></svg></a><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const s=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Copy";function n(){t.innerHTML="Copied",setTimeout(()=>{t.innerHTML="Copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),n();return}const s=document.createRange();s.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(s);try{document.execCommand("copy"),n()}catch{}o.removeRange(s)}),e.parentNode.appendChild(t)})</script></main></body><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script>const images=Array.from(document.querySelectorAll(".blog-content img"));images.forEach(e=>{mediumZoom(e,{margin:10,scrollOffset:40,container:null,template:null,background:"rgba(0, 0, 0, 0.5)"})})</script><script src=/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin=anonymous defer></script></html>