<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogs on Horseman, pass by.</title><link>https://10iA0.github.io/blog/</link><description>Recent content in Blogs on Horseman, pass by.</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 03 Aug 2022 09:27:00 +0000</lastBuildDate><atom:link href="https://10iA0.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Development Environment on WSL</title><link>https://10iA0.github.io/blog/development-environment-on-wsl/</link><pubDate>Wed, 03 Aug 2022 09:27:00 +0000</pubDate><guid>https://10iA0.github.io/blog/development-environment-on-wsl/</guid><description>&lt;p>After configuration of WSL, install Git, Anaconda, PostgreSQL and GUI apps used in WSL.&lt;/p></description></item><item><title>WSL Introduction</title><link>https://10iA0.github.io/blog/wsl-introduction/</link><pubDate>Mon, 25 Jul 2022 20:13:00 +0000</pubDate><guid>https://10iA0.github.io/blog/wsl-introduction/</guid><description>&lt;p>How to use and run Windows Subsystem for Linux?&lt;/p></description></item><item><title>Hadoop-Running a cluster-Start and stop HDFS and YARN automatically</title><link>https://10iA0.github.io/blog/hadoop-running-a-cluster-start-and-stop-hdfs-and-yarn-automatically/</link><pubDate>Wed, 23 Jun 2021 22:08:00 +0000</pubDate><guid>https://10iA0.github.io/blog/hadoop-running-a-cluster-start-and-stop-hdfs-and-yarn-automatically/</guid><description>&lt;p>3 virtual machines were prepated, and JDK, Hadoop have installed and environmental variables have configurated on them. When I do big data computing, the servers shoud be communicated with each other. If I use &lt;code>ssh&lt;/code> directelly, it will report &lt;code>Host key verification failed&lt;/code>. So, I need make ssh login without password. Futhermore, I would like to start and stop cluster manually. So, I need write a script that could start and stop cluster automatically.&lt;/p></description></item><item><title>Hadoop-Running a cluster-Start and stop functions on HDFS and YARN</title><link>https://10iA0.github.io/blog/hadoop-running-a-cluster-start-and-stop-functions-on-hdfs-and-yarn/</link><pubDate>Tue, 22 Jun 2021 18:55:00 +0000</pubDate><guid>https://10iA0.github.io/blog/hadoop-running-a-cluster-start-and-stop-functions-on-hdfs-and-yarn/</guid><description/></item><item><title>Hadoop-Running a cluster-Configurate a cluster (Core, HDFS, MapReduce and YARN)</title><link>https://10iA0.github.io/blog/hadoop-running-a-cluster-configurate-a-cluster/</link><pubDate>Tue, 22 Jun 2021 12:37:00 +0000</pubDate><guid>https://10iA0.github.io/blog/hadoop-running-a-cluster-configurate-a-cluster/</guid><description>&lt;p>3 Virtual machines were prepared already. JDK, Hadoop have installed and environmental variables have configurated on them. If I want to use &lt;code>HDFS&lt;/code>, &lt;code>MapReduce&lt;/code> and &lt;code>YARN&lt;/code>, I need to configurate them appropriate.&lt;/p></description></item><item><title>Hadoop-Running a cluster-Write sync scripts</title><link>https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/</link><pubDate>Mon, 21 Jun 2021 02:18:00 +0000</pubDate><guid>https://10iA0.github.io/blog/hadoop-running-a-cluster-write-sync-scripts/</guid><description>&lt;p>I have prepared 3 virtual machines already in which JDK, Hadoop have installed and environmental variables have configurated. When I do big data computing in a cluster, I need to copy files in a loop from a server to other servers. On the other hand, the existed shell comands are not perfectlly satisfied with my demand. So, I need wite a script &lt;code>xync&lt;/code> with shell.&lt;/p></description></item><item><title>Hadoop-Prerequisites-Preparation on servers</title><link>https://10iA0.github.io/blog/hadoop-prerequisites-preparation-on-servers/</link><pubDate>Tue, 15 Jun 2021 13:38:00 +0000</pubDate><guid>https://10iA0.github.io/blog/hadoop-prerequisites-preparation-on-servers/</guid><description>&lt;p>Prepare 3 servers and set up the development environment on each servers for big data computing. I have no configurated instances on Cloud Server, like AWS, Alibaba, etc., as my student discount was expired. Fortunatly, I have a new computer which is good enough to run multiple virtual machines.&lt;/p></description></item><item><title>Introduction of PySpark</title><link>https://10iA0.github.io/blog/introduction-of-pyspark/</link><pubDate>Sun, 02 Jun 2019 18:30:00 +0000</pubDate><guid>https://10iA0.github.io/blog/introduction-of-pyspark/</guid><description/></item><item><title>Implementing a data warehouse on AWS</title><link>https://10iA0.github.io/blog/implementing-a-data-warehouse-on-aws/</link><pubDate>Mon, 20 May 2019 22:13:00 +0000</pubDate><guid>https://10iA0.github.io/blog/implementing-a-data-warehouse-on-aws/</guid><description/></item><item><title>Introduction to Data Warehouse</title><link>https://10iA0.github.io/blog/introduction-to-data-warehouse/</link><pubDate>Wed, 01 May 2019 18:30:00 +0000</pubDate><guid>https://10iA0.github.io/blog/introduction-to-data-warehouse/</guid><description/></item><item><title>Location Analysis</title><link>https://10iA0.github.io/blog/location-analysis/</link><pubDate>Thu, 25 Oct 2018 20:32:00 +0000</pubDate><guid>https://10iA0.github.io/blog/location-analysis/</guid><description>&lt;p>“点位分析”是IoT洗衣业态最重要的分析之一，因为通过互联网，尤其是数据分析，赋能之后，我们与竞品的直接差异就是是否存在有效的&lt;strong>数据运营&lt;/strong>。数据化运营犹如开车，当我们踩一脚油门的时候，仪表盘立刻会有所反应，就算我们身体感受不到变化，我们也能通过仪表盘感受变化。&lt;/p></description></item><item><title>Postgresql on Data Analysis</title><link>https://10iA0.github.io/blog/postgresql-on-data-analysis/</link><pubDate>Sun, 25 Mar 2018 16:43:00 +0000</pubDate><guid>https://10iA0.github.io/blog/postgresql-on-data-analysis/</guid><description/></item><item><title>Anaconda Operation</title><link>https://10iA0.github.io/blog/anaconda-operation/</link><pubDate>Wed, 07 Feb 2018 18:21:43 +0000</pubDate><guid>https://10iA0.github.io/blog/anaconda-operation/</guid><description>&lt;p>The key points of using anaconda in data analysis.&lt;/p></description></item><item><title>Jupyter Installation</title><link>https://10iA0.github.io/blog/jupyter-installation/</link><pubDate>Fri, 02 Feb 2018 18:52:10 +0000</pubDate><guid>https://10iA0.github.io/blog/jupyter-installation/</guid><description/></item><item><title>Anaconda Installation</title><link>https://10iA0.github.io/blog/anaconda-installation/</link><pubDate>Thu, 01 Feb 2018 16:43:00 +0000</pubDate><guid>https://10iA0.github.io/blog/anaconda-installation/</guid><description>&lt;p>The steps of installing anaconda.&lt;/p></description></item><item><title>Python in 10 Minutes</title><link>https://10iA0.github.io/blog/python-in-10-minutes/</link><pubDate>Mon, 25 Sep 2017 16:43:00 +0000</pubDate><guid>https://10iA0.github.io/blog/python-in-10-minutes/</guid><description>&lt;p>Python.os&lt;/p></description></item><item><title>SQL in 10 Minutes</title><link>https://10iA0.github.io/blog/sql-in-10-minutes-/</link><pubDate>Tue, 25 Jul 2017 20:22:00 +0000</pubDate><guid>https://10iA0.github.io/blog/sql-in-10-minutes-/</guid><description>&lt;p>Here are key points in DML language.&lt;/p></description></item></channel></rss>